import { getOpenAIProxyClient } from '@/lib/openai-proxy'
import { calculateGPTCost, logApiCost } from '@/lib/openai'
import { WorkflowRetry } from '@/lib/retry-logic'
import { PromptService } from './prompts'
import type { Language, TranslationMode, TranslationResult } from './index'
import type { PromptContext } from './prompts'

export class SecureTranslationService {
  /**
   * Translate text using GPT-4o-mini via secure proxy
   */
  static async translate(
    text: string,
    fromLang: Language,
    toLang: Language,
    mode: TranslationMode = 'casual',
    context?: PromptContext
  ): Promise<TranslationResult & { inputTokens: number; outputTokens: number }> {
    const startTime = Date.now()
    
    console.log('ðŸ”¥ðŸ”¥ðŸ”¥ [TRANSLATION-SECURE] STARTING TRANSLATION SERVICE ðŸ”¥ðŸ”¥ðŸ”¥')
    console.log('ðŸ“Š Translation Parameters:')
    console.log('   â€¢ Input text:', `"${text}"`)
    console.log('   â€¢ From language:', fromLang, typeof fromLang)
    console.log('   â€¢ To language:', toLang, typeof toLang)
    console.log('   â€¢ Translation mode:', mode)
    console.log('   â€¢ Context provided:', !!context)
    if (context) {
      console.log('   â€¢ Recent messages:', context.recentMessages?.length || 0)
      console.log('   â€¢ Romantic context:', context.isRomanticContext)
      console.log('   â€¢ Conversation context:', context.conversationContext?.length || 0)
    }
    
    // Generate prompt once (not retried)
    console.log('âš¡ Generating translation prompt...')
    const prompt = PromptService.generateTranslationPrompt(
      fromLang,
      toLang,
      mode,
      context
    );
    
    console.log('ðŸ“ Generated prompt length:', prompt.length, 'characters')
    console.log('ðŸ“ Generated prompt preview:')
    console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')
    console.log('â•‘ PROMPT CONTENT (first 500 chars):')
    console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£')
    console.log(prompt.substring(0, 500))
    if (prompt.length > 500) {
      console.log('...[TRUNCATED]...')
    }
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')

    // Wrap the translation API call with retry logic
    return WorkflowRetry.translation(async () => {
      try {
        console.log('')
        console.log('ðŸ”’ðŸ”’ðŸ”’ [API CALL] CALLING GPT-4o-mini VIA SECURE PROXY ðŸ”’ðŸ”’ðŸ”’')
        console.log('ðŸ”„ Translation direction:', fromLang, 'â†’', toLang)
        
        const requestPayload = {
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: prompt },
            { role: 'user', content: text }
          ],
          temperature: 0.3,
          max_tokens: 1000,
        }
        
        console.log('ðŸ“¤ Request payload:')
        console.log('   â€¢ Model:', requestPayload.model)
        console.log('   â€¢ Temperature:', requestPayload.temperature)
        console.log('   â€¢ Max tokens:', requestPayload.max_tokens)
        console.log('   â€¢ System message length:', requestPayload.messages[0].content.length)
        console.log('   â€¢ User message:', `"${requestPayload.messages[1].content}"`)
        
        console.log('â³ Sending request to OpenAI proxy...')
        
        const completion = await getOpenAIProxyClient().createChatCompletion(requestPayload);

        console.log('')
        console.log('ðŸ“¥ðŸ“¥ðŸ“¥ [API RESPONSE] RECEIVED RESPONSE FROM OPENAI ðŸ“¥ðŸ“¥ðŸ“¥')
        console.log('ðŸ“Š Raw response structure:')
        console.log('   â€¢ Has choices:', !!completion.choices)
        console.log('   â€¢ Choices length:', completion.choices?.length || 0)
        console.log('   â€¢ Has usage:', !!completion.usage)
        
        if (completion.choices && completion.choices.length > 0) {
          console.log('   â€¢ First choice message:', completion.choices[0]?.message)
          console.log('   â€¢ First choice content:', `"${completion.choices[0]?.message?.content}"`)
        }
        
        const translatedText = completion.choices[0]?.message?.content?.trim();
        const usage = completion.usage || { prompt_tokens: 0, completion_tokens: 0 }
        
        console.log('ðŸ” Processing response:')
        console.log('   â€¢ Raw translated text:', `"${completion.choices[0]?.message?.content}"`)
        console.log('   â€¢ Trimmed translated text:', `"${translatedText}"`)
        console.log('   â€¢ Usage prompt tokens:', usage.prompt_tokens)
        console.log('   â€¢ Usage completion tokens:', usage.completion_tokens)
        
        if (!translatedText) {
          console.error('âŒ No translation received from API!')
          throw new Error('No translation received from API');
        }

        // Calculate and log cost
        const cost = calculateGPTCost(usage.prompt_tokens, usage.completion_tokens)
        logApiCost('GPT-4o-mini (secure)', cost)
        
        // Log performance
        console.log(`âš¡ Secure Translation API: ${Date.now() - startTime}ms`)
        
        console.log('')
        console.log('ðŸŽ‰ðŸŽ‰ðŸŽ‰ [SUCCESS] TRANSLATION COMPLETED SUCCESSFULLY ðŸŽ‰ðŸŽ‰ðŸŽ‰')
        console.log('ðŸ“ Final result:')
        console.log('   â€¢ Original text:', `"${text}"`)
        console.log('   â€¢ Translated text:', `"${translatedText}"`)
        console.log('   â€¢ Original language:', fromLang)
        console.log('   â€¢ Target language:', toLang)
        console.log('   â€¢ Input tokens:', usage.prompt_tokens)
        console.log('   â€¢ Output tokens:', usage.completion_tokens)
        console.log('   â€¢ Total cost: $', cost.toFixed(6))
        console.log('ðŸ”¥ðŸ”¥ðŸ”¥ [TRANSLATION-SECURE] ENDING TRANSLATION SERVICE ðŸ”¥ðŸ”¥ðŸ”¥')

        return {
          originalText: text,
          translatedText,
          originalLanguage: fromLang,
          targetLanguage: toLang,
          inputTokens: usage.prompt_tokens,
          outputTokens: usage.completion_tokens,
        };
      } catch (error) {
        console.error('Secure translation error:', error);
        
        // Enhance error with retry information
        const enhancedError = error as any
        enhancedError.isNetworkError = true // Most translation failures are network-related
        
        throw enhancedError
      }
    }, (attempt, error) => {
      console.warn(`ðŸ”’ Secure translation retry attempt ${attempt}:`, error.message)
    })
  }

  /**
   * Get context for translation from recent conversation
   */
  static buildTranslationContext(recentMessages: string[]): PromptContext {
    return {
      recentMessages: recentMessages.slice(-5), // Last 5 messages
      isRomanticContext: this.detectRomanticContext(recentMessages)
    };
  }

  /**
   * Detect if conversation has romantic context for emoji enhancement
   */
  static detectRomanticContext(recentMessages: string[]): boolean {
    const romanticKeywords = [
      'love', 'miss', 'beautiful', 'date', 'kiss', 'heart', 'darling',
      'honey', 'sweetheart', 'cute', 'sexy', 'gorgeous', 'handsome',
      'amor', 'te amo', 'hermosa', 'guapo', 'bonita', 'cariÃ±o',
      'amo', 'saudade', 'linda', 'lindo', 'querida', 'querido'
    ];

    const allText = recentMessages.join(' ').toLowerCase();
    return romanticKeywords.some(keyword => allText.includes(keyword));
  }
}